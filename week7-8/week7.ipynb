{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AfnlcwOWS5l"
      },
      "source": [
        "In this work, you are required to build a GNN training pipline. Then you can truly use the Graph Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H0-sw8zbcrn"
      },
      "outputs": [],
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/repo.html\n",
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cpu.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex3YFUE3Whks"
      },
      "source": [
        "First, we need to download the dataset and load data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLg7RaF6WRTt"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "dataset = Planetoid(\"./\", \"Cora\", transform=T.NormalizeFeatures())\n",
        "data = dataset[0]\n",
        "\n",
        "x = data.x\n",
        "edge_index = data.edge_index\n",
        "edge_weight = data.edge_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MA85AI9b8yX"
      },
      "source": [
        "Then, you need to implement a GNN model. You may copy the GCNConv from your work two weeks ago, and build the model with the convolution layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4La5uI1cQQA"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "class PyG_GCNConv(MessagePassing):\n",
        "  def __init__(\n",
        "      self,\n",
        "      in_channel,\n",
        "      out_channel,\n",
        "  ):\n",
        "    super(PyG_GCNConv, self).__init__()\n",
        "    self.in_channel = in_channel\n",
        "    self.out_channel = out_channel\n",
        "    self.W = nn.Parameter(torch.ones((in_channel, out_channel)))\n",
        "    self.b = nn.Parameter(torch.ones(out_channel))\n",
        "\n",
        "  def forward(self,x, edge_index, edge_weight):\n",
        "    return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "    \n",
        "  def message(self,x_j, edge_weight):\n",
        "    return edge_weight.view(-1,1) * x_j\n",
        "\n",
        "  def update(self, aggr_out):\n",
        "    return aggr_out @ self.W + self.b\n",
        "  \n",
        "class PyG_GCN(nn.Module):\n",
        "    def __init__(self,in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.conv1 = PyG_GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = PyG_GCNConv(hidden_channels, out_channels)\n",
        "    def forward(self,x,edge_index,edge_weight):\n",
        "       x = self.conv1(x,edge_index,edge_weight)\n",
        "       x = x.relu()\n",
        "       x = self.conv2(x,edge_index,edge_weight)\n",
        "       return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz1whBYkcdtx"
      },
      "source": [
        "Building the training and evaluation part, this is similar to the work in week4. Our downstream task is just node classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMlTRvwGcmFw"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.logging import log\n",
        "import torch   \n",
        "# Build your training pipeline\n",
        "hidden_dim = 16\n",
        "lr = 0.001\n",
        "epochs = 100\n",
        "model = PyG_GCN(dataset.num_features, hidden_dim, dataset.num_classes)\n",
        "# optimizer = torch.optim.Adam(\n",
        "#     dict(params=model.parameters(), weight_decay=5e-4), lr=lr)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "def train():\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  out = model(data.x, data.edge_index,data.edge_weight)\n",
        "  mask = data.x.train_mask\n",
        "  loss = loss_func(out[mask], data.y[mask])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return float(loss)\n",
        "   \n",
        "@torch.no_grad()\n",
        "def test():\n",
        "  model.eval()\n",
        "  pred = model(data.x, data.edge_index, data.edge_weight).argmax(dim=-1)\n",
        "\n",
        "  accs = []\n",
        "  for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "      accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "  return accs\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "  loss = train()\n",
        "  train_acc, val_acc, tmp_test_acc = test()\n",
        "  if val_acc > best_val_acc:\n",
        "      best_val_acc = val_acc\n",
        "      test_acc = tmp_test_acc\n",
        "  log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pav74NceOl5"
      },
      "source": [
        "Now, you can train the GCN model with PyG. Next, you may try using the DGL to implement the similiar function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNDS5VDreXgC"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl import AddSelfLoop\n",
        "from dgl.data import CoraGraphDataset\n",
        "import dgl.function as fn\n",
        "transform = (\n",
        "        AddSelfLoop()\n",
        "    )\n",
        "data = CoraGraphDataset(transform=transform)\n",
        "g = data[0]\n",
        "features = g.ndata[\"feat\"]\n",
        "labels = g.ndata[\"label\"]\n",
        "masks = g.ndata[\"train_mask\"], g.ndata[\"val_mask\"], g.ndata[\"test_mask\"]\n",
        "\n",
        "\n",
        "class DGL_GCNConv(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel):\n",
        "    super(DGL_GCNConv, self).__init__()\n",
        "    self.in_channel = in_channel\n",
        "    self.out_channel = out_channel\n",
        "    self.W = nn.Parameter(torch.ones(in_channel, out_channel))\n",
        "    self.b = nn.Parameter(torch.ones(out_channel))\n",
        "\n",
        "  def forward(self, g, h, edge_weight):\n",
        "    # Your code here\n",
        "    g.ndata['h'] = h\n",
        "    g.edata['edge_weight'] = edge_weight\n",
        "    g.ndata['hm'] = g.ndata['h'] @ self.W\n",
        "    g.update_all(fn.u_mul_e('hm', 'edge_weight', 'm'), fn.sum('m', 'h'))\n",
        "    g.ndata['h'] = g.ndata['h'] + self.b\n",
        "        \n",
        "    return g.ndata['h']\n",
        "    # End code here\n",
        "\n",
        "class DGL_GCN(nn.Module):\n",
        "  def __init__(self,in_feats,out_feats):\n",
        "    super().__init__()\n",
        "    hid_feats = 16\n",
        "    self.conv1 = DGL_GCNConv(in_feats,hid_feats)\n",
        "    self.conv2 = DGL_GCNConv(hid_feats,hid_feats)\n",
        "    self.conv3 = DGL_GCNConv(hid_feats,out_feats)\n",
        "  def forward(self, graph, inputs):\n",
        "    edge_weight = torch.ones(graph.number_of_edges())\n",
        "    h = self.conv1(graph, inputs,edge_weight)\n",
        "    h = F.relu(h)\n",
        "    edge_weight = torch.ones(graph.number_of_edges())\n",
        "    h = self.conv2(graph, h,edge_weight)\n",
        "    h = F.relu(h)\n",
        "    edge_weight = torch.ones(graph.number_of_edges())\n",
        "    h = self.conv3(graph, h,edge_weight)\n",
        "    return h\n",
        "\n",
        "def train(g, features, labels, masks, model):\n",
        "  n_features = features.shape[1]\n",
        "  n_labels = int(labels.max().item() + 1)\n",
        "  model = DGL_GCN(n_features, n_labels)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "  for epoch in range(100):\n",
        "    model.train()\n",
        "    logits = model(g, features)\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    loss = F.nll_loss(logp[masks[0]], labels[masks[0]])\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc = (logp[masks[0]].argmax(1) == labels[masks[0]]).float().mean()\n",
        "    val_acc = evaluate(g, features, labels, masks[1], model)\n",
        "    print(f'Epoch {epoch}, Loss: {loss.item():.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}')\n",
        "\n",
        "def evaluate(g, features, labels, mask, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(g, features)\n",
        "    logits = logits[mask]\n",
        "    labels = labels[mask]\n",
        "    _, indices = torch.max(logits, dim=1)\n",
        "    correct = torch.sum(indices == labels)\n",
        "    return correct.item() * 1.0 / len(labels)\n",
        "\n",
        "model = DGL_GCN(features.shape[1], 16)\n",
        "print(\"Training...\")\n",
        "train(g, features, labels, masks, model)\n",
        "\n",
        "# test the model\n",
        "print(\"Testing...\")\n",
        "acc = evaluate(g, features, labels, masks[2], model)\n",
        "print(\"Test accuracy {:.4f}\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG3acaBaf0Uj"
      },
      "source": [
        "If you find it hard to implement, you may refer to the official implementation of the GNN training, like [PyG](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py) and [DGL](https://github.com/dmlc/dgl/blob/master/examples/pytorch/gcn/train.py)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
